---
## Front matter
title: "Отчёт по лабораторной работе №16"
subtitle: "Программный RAID"
author: "Щемелев Илья Владимирович"

## Generic otions
lang: ru-RU
toc-title: "Содержание"

## Bibliography
bibliography: bib/cite.bib
csl: pandoc/csl/gost-r-7-0-5-2008-numeric.csl

## Pdf output format
toc: true
toc-depth: 2
lof: true
lot: true
fontsize: 12pt
linestretch: 1.5
papersize: a4
documentclass: scrreprt
## I18n polyglossia
polyglossia-lang:
  name: russian
  options:
    - spelling=modern
    - babelshorthands=true
polyglossia-otherlangs:
  name: english
## I18n babel
babel-lang: russian
babel-otherlangs: english
## Fonts
mainfont: IBM Plex Serif
romanfont: IBM Plex Serif
sansfont: IBM Plex Sans
monofont: IBM Plex Mono
mathfont: STIX Two Math
mainfontoptions: Ligatures=Common,Ligatures=TeX,Scale=0.94
romanfontoptions: Ligatures=Common,Ligatures=TeX,Scale=0.94
sansfontoptions: Ligatures=Common,Ligatures=TeX,Scale=MatchLowercase,Scale=0.94
monofontoptions: Scale=MatchLowercase,Scale=0.94,FakeStretch=0.9
mathfontoptions:
## Biblatex
biblatex: true
biblio-style: "gost-numeric"
biblatexoptions:
  - parentracker=true
  - backend=biber
  - hyperref=auto
  - language=auto
  - autolang=other*
  - citestyle=gost-numeric
## Pandoc-crossref LaTeX customization
figureTitle: "Рис."
tableTitle: "Таблица"
listingTitle: "Листинг"
lofTitle: "Список иллюстраций"
lotTitle: "Список таблиц"
lolTitle: "Листинги"
## Misc options
indent: true
header-includes:
  - \usepackage{indentfirst}
  - \usepackage{float}
  - \floatplacement{figure}{H}
---

# Цель работы

Освоить работу с RAID-массивами при помощи утилиты mdadm.

# Ход выполнения

## Создание программного RAID-массива (RAID 1)

1. Виртуальная машина была запущена, после чего получены полномочия администратора.  
   Далее выполнена проверка наличия ранее добавленных дисков.  
   В системе дополнительные диски определились как **/dev/sdc**, **/dev/sdd** и **/dev/sde**, каждый объёмом **512 MiB**.

   ![Проверка подключённых дисков](Screenshot_1.png)

2. На каждом из обнаруженных дисков был создан один раздел на весь доступный объём.  
   В процессе была автоматически создана таблица разделов типа **DOS (MBR)**.  
   В результате на каждом диске появился раздел вида **/dev/sdX1**.

   ![Создание раздела на диске](Screenshot_2.png)

3. После создания разделов был проверен их тип.  
   Для всех созданных разделов был получен идентификатор **83**, что соответствует типу **Linux**.  
   Это означает, что по умолчанию разделы не предназначены для использования в RAID.

   ![Проверка типа разделов](Screenshot_3.png)

4. Далее были просмотрены доступные типы разделов, относящиеся к RAID.  
   Определено, что для программного RAID используется тип **fd — Linux raid autodetect**.  
   После этого тип всех созданных разделов был изменён на **fd**.  
   Изменения таблицы разделов успешно применены и перечитаны ядром системы.

   ![Изменение типа разделов на RAID](Screenshot_3.png)

5. Выполнена повторная проверка состояния и структуры всех трёх дисков.  
   Каждый диск имеет один раздел размером **511 MiB**, тип таблицы разделов — **dos**, тип раздела — **Linux raid autodetect (fd)**.  
   Диски полностью готовы к включению в RAID-массив.

   ![Состояние дисков после изменения типа](Screenshot_4.png)

6. С использованием утилиты **mdadm** был создан программный RAID-массив уровня **RAID 1** из двух разделов.  
   В процессе создания массива система вывела предупреждение о формате метаданных и предложила включить write-intent bitmap, от чего было отказано.  
   После подтверждения массив **/dev/md0** был успешно создан.

   Состояние массива проверено:  
   массив активен, уровень — **raid1**, оба диска находятся в рабочем состоянии.

   ![Создание RAID 1 и проверка состояния](Screenshot_5.png)

7. Выполнен детальный просмотр параметров массива.  
   RAID-массив находится в состоянии **clean**, количество активных устройств — **2**, отказавших и резервных устройств нет.  
   Оба диска работают в режиме **active sync**, что подтверждает корректную работу зеркалирования.

   ![Детальная информация о RAID-массиве](Screenshot_6.png)

8. На созданном RAID-массиве была создана файловая система **ext4**.  
   Массив был смонтирован в каталог **/data**.  
   Для обеспечения автоматического монтирования при загрузке системы в файл **/etc/fstab** добавлена соответствующая запись.

   ![Настройка автомонтирования RAID](Screenshot_7.png)

9. Для проверки отказоустойчивости массива был смоделирован сбой одного из дисков.  
   Один из разделов был помечен как сбойный и удалён из массива.  
   После этого в массив был добавлен новый раздел с третьего диска.  
   Проверка состояния показала, что массив продолжает корректно работать, оба активных диска находятся в состоянии синхронизации, состояние массива — **clean**.

   ![Имитация отказа и замена диска в RAID](Screenshot_8.png)

10. По завершении лабораторной работы RAID-массив был корректно удалён.  
    Сначала массив был размонтирован и остановлен, после чего с каждого из использованных разделов были удалены RAID-метаданные.  
    Система приведена в исходное состояние.

   ![Удаление RAID-массива и очистка метаданных](Screenshot_9.png)

## RAID-массив с горячим резервом (hot spare)

1. После запуска виртуальной машины были получены полномочия администратора.  
   Далее с использованием утилиты **mdadm** создан программный RAID-массив уровня **RAID 1** из двух разделов **/dev/sdd1** и **/dev/sde1**.  
   В процессе создания массива система выдала рекомендации по использованию write-intent bitmap и предупреждение о формате метаданных.  
   После подтверждения операции массив **/dev/md0** был успешно инициализирован и запущен.

2. После создания массива в него был добавлен третий раздел **/dev/sdc1**, который использован в качестве горячего резерва (hot spare).  
   Добавление диска выполнено без остановки массива, что подтверждает возможность динамического управления RAID.

   ![Добавление горячего резервного диска](Screenshot_10.png)

3. RAID-массив был смонтирован, после чего выполнена проверка его состояния.  
   Согласно выводу системных утилит:
   - массив **md0** активен;
   - уровень массива — **raid1**;
   - два диска находятся в состоянии **active sync**;
   - один диск определён как **spare** (горячий резерв);
   - состояние массива — **clean**.  

   Это подтверждает, что массив функционирует корректно и имеет резервное устройство для автоматического восстановления.

   ![Проверка состояния RAID с горячим резервом](Screenshot_11.png)

4. Для проверки отказоустойчивости был смоделирован сбой одного из рабочих дисков массива.  
   Раздел **/dev/sde1** был помечен как неисправный.  
   После этого система автоматически исключила его из массива и задействовала резервный диск **/dev/sdc1**, который перешёл в состояние **active sync**.  
   Массив продолжил работу без остановки и потери доступности данных.

5. Состояние массива после сбоя подтверждает корректную автоматическую перестройку:
   - один диск имеет состояние **faulty**;
   - два оставшихся диска находятся в состоянии **active sync**;
   - массив остаётся в состоянии **clean** и доступен для использования.  

   Данный результат демонстрирует работу механизма горячего резерва и автоматического восстановления RAID 1.

   ![Состояние RAID после сбоя диска](Screenshot_12.png)

6. По завершении эксперимента RAID-массив был корректно удалён.  
   Массив предварительно размонтирован, затем остановлен, после чего с каждого из задействованных разделов были удалены RAID-метаданные.  
   Это гарантирует отсутствие конфликтов при последующем использовании дисков.

   ![Остановка RAID и очистка метаданных](Screenshot_13.png)

## Преобразование массива RAID 1 в RAID 5

1. После запуска виртуальной машины были получены полномочия администратора.  
   Далее с использованием утилиты **mdadm** создан программный RAID-массив уровня **RAID 1** из двух разделов **/dev/sdd1** и **/dev/sde1**.  
   В процессе создания массива система вывела предупреждение о метаданных и рекомендацию включить write-intent bitmap, после чего массив **/dev/md0** был успешно запущен.  
   Затем в массив добавлен третий диск **/dev/sdc1** (на данном этапе он используется как резервный, spare).

   ![Создание RAID1 и добавление третьего диска](Screenshot_14.png)

2. RAID-массив был смонтирован, после чего выполнена проверка его состояния.  
   По результатам проверки:
   - уровень массива — **raid1**;
   - состояние — **clean**;
   - активных устройств — **2** (оба в режиме **active sync**);
   - всего устройств — **3**, из них **1** находится в состоянии **spare** (горячий резерв).  

   Это означает, что массив RAID 1 работает штатно, а третий диск подготовлен для автоматической замены при отказе одного из основных дисков.

   ![Состояние RAID1 перед преобразованием](Screenshot_15.png)

3. Выполнено изменение уровня массива с **RAID 1** на **RAID 5** командой изменения типа массива.  
   После выполнения операции уровень массива в выводе `mdadm --detail` изменился на **raid5**, при этом конфигурация устройств ещё не изменилась:  
   активных дисков по-прежнему **2**, а третий диск остаётся **spare**.  
   Состояние массива сохраняется как **clean**, что указывает на корректное применение новой конфигурации уровня.

   ![Изменение уровня массива на RAID5](Screenshot_16.png)

4. Далее выполнено расширение массива до трёх устройств (изменение количества дисков в RAID 5).  
   В процессе проверки была допущена ошибка при обращении к устройству (`/dev/md` вместо `/dev/md0`), после чего команда была повторена корректно.  
   После расширения:
   - уровень массива — **raid5**;
   - активных устройств — **3**;
   - резервных устройств — **0**;
   - все три диска (**/dev/sdd1**, **/dev/sde1**, **/dev/sdc1**) находятся в состоянии **active sync**;  
   - размер массива увеличился до ~**1020 MiB**, что соответствует объединению трёх дисков по ~510 MiB с учётом избыточности RAID 5.

   ![Расширение RAID5 до трёх дисков и проверка состояния](Screenshot_17.png)

5. По завершении преобразования массив был корректно удалён и выполнена очистка метаданных.  
   Массив размонтирован и остановлен, после чего выполнено удаление RAID superblock на всех задействованных разделах (**/dev/sdd1**, **/dev/sde1**, **/dev/sdc1**).  
   Это исключает конфликты при повторном использовании дисков.

   ![Остановка массива и очистка метаданных](Screenshot_18.png)

6. Для предотвращения ошибок при последующих загрузках системы запись автомонтирования массива в файле **/etc/fstab** была закомментирована.  
   Таким образом, система больше не пытается автоматически монтировать несуществующее устройство **/dev/md0** в каталог **/data**.

   ![Комментирование записи /dev/md0 в /etc/fstab](Screenshot_19.png)

# Контрольные вопросы

1. **RAID (Redundant Array of Independent Disks)** — это технология объединения нескольких физических дисков в один логический массив с целью повышения производительности, отказоустойчивости или сочетания этих характеристик.  
   RAID позволяет распределять данные между дисками по определённому алгоритму, обеспечивая либо ускорение операций ввода-вывода, либо сохранность данных при выходе из строя одного или нескольких накопителей.

2. На сегодняшний день используются следующие основные типы RAID-массивов:

   - **RAID 0** — массив с чередованием данных (striping) без избыточности;
   - **RAID 1** — зеркальный массив (mirroring);
   - **RAID 2** — массив с кодами Хэмминга (практически не используется);
   - **RAID 3** — чередование данных с выделенным диском чётности;
   - **RAID 4** — блочное чередование с выделенным диском чётности;
   - **RAID 5** — блочное чередование с распределённой чётностью;
   - **RAID 6** — аналог RAID 5 с двойной чётностью;
   - **RAID 10 (1+0)** — комбинация RAID 1 и RAID 0;
   - **RAID 50, RAID 60** — комбинированные уровни для систем с большим количеством дисков.

   На практике наибольшее распространение получили RAID 0, RAID 1, RAID 5, RAID 6 и RAID 10.

3. Характеристика основных уровней RAID:

   - **RAID 0**  
     Алгоритм работы основан на чередовании блоков данных между несколькими дисками.  
     Избыточность отсутствует, каждый файл разбивается на части и записывается параллельно.  
     Назначение — максимальное увеличение производительности операций чтения и записи.  
     Отказ любого диска приводит к полной потере данных.  
     Примеры применения: временные хранилища, рабочие каталоги, системы обработки видео и графики, где важна скорость и допустима потеря данных.

   - **RAID 1**  
     Алгоритм работы основан на зеркалировании данных: информация полностью дублируется на каждом диске массива.  
     Обеспечивает высокую отказоустойчивость — при выходе из строя одного диска данные сохраняются.  
     Эффективный объём массива равен объёму одного диска.  
     Примеры применения: серверы баз данных, системные разделы, критически важные данные, требующие высокой надёжности.

   - **RAID 5**  
     Использует блочное чередование данных с распределённой информацией чётности по всем дискам массива.  
     Позволяет восстановить данные при отказе одного диска без полной потери информации.  
     Обеспечивает баланс между производительностью, отказоустойчивостью и эффективным использованием дискового пространства.  
     Примеры применения: файловые серверы, серверы общего назначения, корпоративные хранилища данных.

   - **RAID 6**  
     Является развитием RAID 5 и использует двойную распределённую чётность.  
     Позволяет выдержать одновременный отказ двух дисков без потери данных.  
     Требует больше вычислительных ресурсов и дискового пространства по сравнению с RAID 5.  
     Примеры применения: крупные серверные хранилища, системы резервного копирования, архивные хранилища с повышенными требованиями к надёжности.

# Заключение

В ходе лабораторной работы была изучена технология программного RAID и отработаны практические навыки создания, настройки и управления RAID-массивами с использованием утилиты **mdadm**.  
Были рассмотрены режимы зеркалирования, горячего резерва и преобразования уровня массива, а также выполнена проверка отказоустойчивости и корректного восстановления данных.
